{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Apache_Spark_Artist_Recommendation_System.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYIrMHB5VwG1"
      },
      "source": [
        "# **Building An Artist Recommender System**\r\n",
        "As its name implies, a recommender system is a tool that helps predicting what a user may or may not like among a list of given items. In some sense, you can view this as an alternative to content search, as recommendation engines help users discover products or content that they may not come across otherwise. For example, Facebook suggests friends and pages to users. Youtube recommends videos which users may be interested in. Amazon suggests the products which users may need... Recommendation engines engage users to services, can be seen as a revenue optimization process, and in general help maintaining interest in a service.\r\n",
        "\r\n",
        "In this notebook, I demonstrate how to build a simple recommender system: we focus on music recommendations, and we use a simple algorithm to predict which items users might like, that is called ALS -- alternating least squares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2sVVl7rWDJI"
      },
      "source": [
        "# Goals\r\n",
        "In this notebook, I expect to:\r\n",
        "\r\n",
        "- Revisit (or learn) recommender algorithms\r\n",
        "\r\n",
        "- Understand the idea of Matrix Factorization and the ALS algorithm (serial and parallel versions)\r\n",
        "\r\n",
        "- Build a simple model for a real usecase: music recommender system\r\n",
        "\r\n",
        "- Understand how to validate the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWKX9LbTWNs3"
      },
      "source": [
        "## Steps\r\n",
        "- Inspect the data using Spark SQL, and build some basic, but very valuable knowledge about the information we have at hand\r\n",
        "- Formally define what is a sensible algorithm to achieve our goal: given the \"history\" of user taste for music, recommend new music to discover. Essentialy, we want to build a statistical model of user preferences such that we can use it to \"predict\" which additional music the user could like\r\n",
        "- With our formal definition at hand, we will learn different ways to implement such an algorithm. Our goal here is to illustrate what are the difficulties to overcome when implementing a (parallel) algorithm\r\n",
        "- Finally, we will focus on an existing implementation, available in the Apache Spark MLLib, which we will use out of the box to build a reliable statistical model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yrz3V06Wada"
      },
      "source": [
        "**Furthermore:**   \r\n",
        "\r\n",
        "One important topic that I will cover in the Notebooks is how to validate the results we obtain, and how to choose good parameters to train models especially when using an \"opaque\" library for doing the job. As a consequence, I will focus on the statistical validation of our recommender system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x2oxFT6WjVg"
      },
      "source": [
        "## 1. Data\r\n",
        "Understanding data is one of the most important part when designing any machine learning algorithm. In this notebook, I will use a data set published by Audioscrobbler - a music recommendation system for last.fm. Audioscrobbler is also one of the first internet streaming radio sites, founded in 2002. It provided an open API for “scrobbling”, or recording listeners’ plays of artists’ songs. last.fm used this information to build a powerful music recommender engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1MidhbEWo2y"
      },
      "source": [
        "## 1.1. Data schema\r\n",
        "Unlike a rating dataset which contains information about users' preference for products (one star, 3 stars, and so on), the datasets from Audioscrobbler only has information about events: specifically, it keeps track of how many times a user played songs of a given artist and the names of artists. That means it carries less information than a rating: in the literature, this is called explicit vs. implicit ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te7vK1ihXw4L"
      },
      "source": [
        "MisspelledArtistID\t| StandardArtistID  \r\n",
        "...\t| ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZfO1eZVW1S5"
      },
      "source": [
        "## Reading material\r\n",
        "- Implicit Feedback for Inferring User Preference: A Bibliography\r\n",
        "- Comparing explicit and implicit feedback techniques for web retrieval: TREC-10 interactive track report\r\n",
        "- Probabilistic Models for Data Combination in Recommender Systems  \r\n",
        "\r\n",
        "The data we use in this Notebook is available in 3 files (these files are stored in our HDFS layer, in the directory /dataset/):\r\n",
        "\r\n",
        "- **user_artist_data.txt**: It contains about 140,000+ unique users, and 1.6 million unique artists. About 24.2 million users’ plays of artists’ are recorded, along with their count. It has 3 columns separated by spaces:      \r\n",
        "\r\n",
        "UserID | ArtistID | PlayCount\r\n",
        "--- | --- | ---\r\n",
        "...\t| ...\t| ...    \r\n",
        "\r\n",
        "- **artist_data.txt** : It prodives the names of each artist by their IDs. It has 2 columns separated by tab characters (\\t).  \r\n",
        "\r\n",
        "\r\n",
        " ArtistID | Name\r\n",
        "--- | ---   \r\n",
        "...\t| ...\t  \r\n",
        "\r\n",
        "\r\n",
        "- **artist_alias.txt**: Note that when plays are scrobbled, the client application submits the name of the artist being played. This name could be misspelled or nonstandard. For example, \"The Smiths\", \"Smiths, The\", and \"the smiths\" may appear as distinct artist IDs in the data set, even though they are plainly the same. artist_alias.txt maps artist IDs that are known misspellings or variants to the canonical ID of that artist. The data in this file has 2 columns separated by tab characters (\\t).\r\n",
        "\r\n",
        "\r\n",
        "MisspelledArtistID\t| StandardArtistID  \r\n",
        "--- | ---\r\n",
        "...\t| ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-_Kc4HZLHK"
      },
      "source": [
        "## Data Exploration: simple descriptive statistics\r\n",
        "In order to choose or design a suitable algorithm for achieving our goals, given the data we have, we should first understand data characteristics. To start, we import the necessary packages to work with regular expressions, Data Frames, and other nice features of our programming environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjr_6ESZUWoX",
        "outputId": "44370d1b-ba38-4b6f-ca30-d259e7870943"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\r\n",
        "!tar -xvf spark-3.0.1-bin-hadoop3.2.tgz\r\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark-3.0.1-bin-hadoop3.2/\n",
            "spark-3.0.1-bin-hadoop3.2/RELEASE\n",
            "spark-3.0.1-bin-hadoop3.2/examples/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/users.avro\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/dir1/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/users.orc\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/users.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/people.txt\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/user.avsc\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/people.csv\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/employees.json\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/resources/people.json\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scripts/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/als.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/r/dataframe.R\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/kmeans.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/als.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/pagerank.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/wordcount.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/pi.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/src/main/python/sort.py\n",
            "spark-3.0.1-bin-hadoop3.2/examples/jars/\n",
            "spark-3.0.1-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/data/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/ridge-data/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/license.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/images/license.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/gmm_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/kmeans_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/pagerank_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/pic_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/als/\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/mllib/als/test.data\n",
            "spark-3.0.1-bin-hadoop3.2/data/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/data/streaming/AFINN-111.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/graphx/\n",
            "spark-3.0.1-bin-hadoop3.2/data/graphx/followers.txt\n",
            "spark-3.0.1-bin-hadoop3.2/data/graphx/users.txt\n",
            "spark-3.0.1-bin-hadoop3.2/yarn/\n",
            "spark-3.0.1-bin-hadoop3.2/yarn/spark-3.0.1-yarn-shuffle.jar\n",
            "spark-3.0.1-bin-hadoop3.2/bin/\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-class.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/run-example\n",
            "spark-3.0.1-bin-hadoop3.2/bin/run-example.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-class\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-class2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/find-spark-home\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-submit\n",
            "spark-3.0.1-bin-hadoop3.2/bin/pyspark\n",
            "spark-3.0.1-bin-hadoop3.2/bin/find-spark-home.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/docker-image-tool.sh\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-shell.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-sql.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/load-spark-env.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/sparkR2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/beeline.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/pyspark.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-shell2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-sql2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/sparkR\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-sql\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-shell\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-submit.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/load-spark-env.sh\n",
            "spark-3.0.1-bin-hadoop3.2/bin/beeline\n",
            "spark-3.0.1-bin-hadoop3.2/bin/sparkR.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/pyspark2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/bin/spark-submit2.cmd\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-thriftserver.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-slaves.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/spark-config.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-master.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-thriftserver.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/spark-daemons.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-all.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-master.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-slave.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-slave.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-slaves.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-history-server.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/stop-history-server.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-all.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/slaves.sh\n",
            "spark-3.0.1-bin-hadoop3.2/sbin/spark-daemon.sh\n",
            "spark-3.0.1-bin-hadoop3.2/README.md\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-scala.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-spire.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-join.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-javassist.html\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-respond.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-janino.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-heapq.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jline.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.0.1-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.0.1-bin-hadoop3.2/LICENSE\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.0.1-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n",
            "spark-3.0.1-bin-hadoop3.2/R/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/sparkr.zip\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/html/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/html/R.css\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/INDEX\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/profile/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/R/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/worker/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n",
            "spark-3.0.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.0.1-bin-hadoop3.2/NOTICE\n",
            "spark-3.0.1-bin-hadoop3.2/jars/\n",
            "spark-3.0.1-bin-hadoop3.2/jars/pyrolite-4.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-common-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-shims-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/nimbus-jose-jwt-4.41.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/stax2-api-3.1.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json4s-ast_2.12-3.6.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-media-jaxb-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-configuration2-2.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-catalyst_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/RoaringBitmap-0.7.45.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-daemon-1.0.13.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/guice-servlet-4.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kubernetes-model-common-4.9.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json-1.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/orc-core-1.5.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/chill_2.12-0.9.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/antlr4-runtime-4.7.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-client-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json4s-scalap_2.12-3.6.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/accessors-smart-1.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/joda-time-2.10.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/okio-1.15.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/gson-2.2.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-hdfs-client-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-mapreduce-client-core-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/guice-4.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-client-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jta-1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-httpclient-3.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/woodstox-core-5.0.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-admin-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-client-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/httpclient-4.5.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/aopalliance-1.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/univocity-parsers-2.9.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/transaction-api-1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-serde-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-auth-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-shims-0.23-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/dnsjava-2.1.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/snappy-java-1.1.7.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-io-2.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/snakeyaml-1.24.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/metrics-json-4.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-mapreduce-client-common-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/okhttp-2.7.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/automaton-1.11-8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/re2j-1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-core_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/okhttp-3.12.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-client-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.10.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/guava-14.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/stream-2.9.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-tags_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/metrics-core-4.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-server-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-annotations-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-cli-1.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-kvstore_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/arrow-vector-0.15.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-api-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-jdbc-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/janino-3.0.16.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/ivy-2.4.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-lang3-3.9.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-hive_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerby-asn1-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/derby-10.12.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-text-1.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-beeline-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-llap-common-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-shims-common-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-server-common-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/generex-1.0.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/objenesis-2.5.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/logging-interceptor-3.12.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-codec-1.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-core-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/core-1.1.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-tags_2.12-3.0.1-tests.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/arrow-format-0.15.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/orc-shims-1.5.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/log4j-1.2.17.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/paranamer-2.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kubernetes-model-4.9.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-crypto-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-metastore-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-common-1.10.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/zstd-jni-1.4.4-3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-mapreduce-client-jobclient-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-container-servlet-core-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-registry-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-lang-2.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-format-2.4.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-common-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/opencsv-2.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jpam-1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerby-pkix-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/ehcache-3.3.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/py4j-0.10.9.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-repl_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-mesos_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json4s-jackson_2.12-3.6.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-cli-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-jaxrs-base-2.9.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/javax.inject-1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-container-servlet-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-common-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/shims-0.7.45.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-core-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jline-2.14.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-identity-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jsp-api-2.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/httpcore-4.4.12.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/ST4-4.0.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerby-xdr-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-hk2-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/orc-mapreduce-1.5.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jersey-server-2.30.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/JTransforms-3.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/javax.servlet-api-3.1.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-graphx_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/arrow-memory-0.15.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-sketch_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-exec-2.3.7-core.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-streaming_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-net-3.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/velocity-1.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerby-config-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-storage-api-2.7.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-common-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-compress-1.8.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/breeze_2.12-1.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/netty-all-4.1.47.Final.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/chill-java-0.9.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/activation-1.1.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-mllib_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-launcher_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-network-common_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerby-util-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jcip-annotations-1.0-1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/token-provider-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/oro-2.0.8.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-jaxrs-json-provider-2.9.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kubernetes-client-4.9.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-simplekdc-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-yarn_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json4s-core_2.12-3.6.6.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/xz-1.5.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/zookeeper-3.4.14.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-column-1.10.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/kerb-util-1.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-sql_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-crypto-1.0.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/javolution-5.5.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/aircompressor-0.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-library-2.12.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/hive-common-2.3.7.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/json-smart-2.3.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/avro-1.8.2.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/minlog-1.3.0.jar\n",
            "spark-3.0.1-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.0.1.jar\n",
            "spark-3.0.1-bin-hadoop3.2/python/\n",
            "spark-3.0.1-bin-hadoop3.2/python/setup.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/functions.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/regression.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/feature.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/base.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tuning.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/clustering.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/stat.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/image.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/fpm.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/param/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/common.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/linalg/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/classification.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tree.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/statcounter.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/status.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/java_gateway.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/regression.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/feature.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/common.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/linalg/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/classification.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tree.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/random.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/resource.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/serializers.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/daemon.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/broadcast.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/listener.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/utils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/testing/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/shell.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/heapq3.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/version.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/rddsampler.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/worker.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/cloudpickle.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/functions.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/column.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/utils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/avro/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/window.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/session.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/types.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/group.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/catalog.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/udf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/conf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/streaming.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/join.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/accumulators.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/resultiterable.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/profiler.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/taskcontext.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/storagelevel.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/traceback_utils.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/files.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/_globals.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/shuffle.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/rdd.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/find_spark_home.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/conf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_util.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_context.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_join.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/__init__.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_coverage/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_coverage/conf/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/userlibrary.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/streaming/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/ages.csv\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/text-test.txt\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/people1.json\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/people_array.json\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/sql/people.json\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/hello/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/hello/hello.txt\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/hello/sub_hello/\n",
            "spark-3.0.1-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.0.1-bin-hadoop3.2/python/README.md\n",
            "spark-3.0.1-bin-hadoop3.2/python/run-tests-with-coverage\n",
            "spark-3.0.1-bin-hadoop3.2/python/MANIFEST.in\n",
            "spark-3.0.1-bin-hadoop3.2/python/.coveragerc\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.mllib.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/index.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.sql.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_static/\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_static/pyspark.css\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_static/copybutton.js\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_static/pyspark.js\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/make.bat\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.resource.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/make2.bat\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_templates/\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/_templates/layout.html\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.streaming.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/Makefile\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/conf.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/docs/pyspark.ml.rst\n",
            "spark-3.0.1-bin-hadoop3.2/python/lib/\n",
            "spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip\n",
            "spark-3.0.1-bin-hadoop3.2/python/lib/pyspark.zip\n",
            "spark-3.0.1-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.0.1-bin-hadoop3.2/python/run-tests.py\n",
            "spark-3.0.1-bin-hadoop3.2/python/pylintrc\n",
            "spark-3.0.1-bin-hadoop3.2/python/run-tests\n",
            "spark-3.0.1-bin-hadoop3.2/python/setup.cfg\n",
            "spark-3.0.1-bin-hadoop3.2/python/.gitignore\n",
            "spark-3.0.1-bin-hadoop3.2/conf/\n",
            "spark-3.0.1-bin-hadoop3.2/conf/fairscheduler.xml.template\n",
            "spark-3.0.1-bin-hadoop3.2/conf/log4j.properties.template\n",
            "spark-3.0.1-bin-hadoop3.2/conf/spark-defaults.conf.template\n",
            "spark-3.0.1-bin-hadoop3.2/conf/metrics.properties.template\n",
            "spark-3.0.1-bin-hadoop3.2/conf/spark-env.sh.template\n",
            "spark-3.0.1-bin-hadoop3.2/conf/slaves.template\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Hbo8KQbPMu"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK4BAe3FbY6t"
      },
      "source": [
        "import findspark\r\n",
        "findspark.init()\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LxPcuUUbbnW",
        "outputId": "e0118161-4a04-49ba-c1d9-4f21dc33b2c0"
      },
      "source": [
        "!pip install https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true\n",
            "\u001b[?25l  Downloading https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from systemml==1.3.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from systemml==1.3.0) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from systemml==1.3.0) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from systemml==1.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: Pillow>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from systemml==1.3.0) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->systemml==1.3.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->systemml==1.3.0) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->systemml==1.3.0) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->systemml==1.3.0) (1.15.0)\n",
            "Building wheels for collected packages: systemml\n",
            "  Building wheel for systemml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for systemml: filename=systemml-1.3.0-cp36-none-any.whl size=9882974 sha256=c7780696180fd888fb50ddcc925cbbdc0e6888de85c1d2ca8d9cb4edbf0f891f\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/bf/28/4344dd13abd8b9b6cbd4032baf4b851873d2e2288a65631fd2\n",
            "Successfully built systemml\n",
            "Installing collected packages: systemml\n",
            "Successfully installed systemml-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_9fxxIYbfC5",
        "outputId": "7c1e52e2-4d01-4aae-8f0b-cbf7ad4b5a29"
      },
      "source": [
        "# Downloading dataset\r\n",
        "!set -e\r\n",
        "\r\n",
        "!mkdir -p dataset\r\n",
        "!cd dataset\r\n",
        "!wget http://www.iro.umontreal.ca/~lisa/datasets/profiledata_06-May-2005.tar.gz\r\n",
        "!tar xvf profiledata_06-May-2005.tar.gz\r\n",
        "!mv profiledata_06-May-2005/* dataset/\r\n",
        "!rm -r profiledata_06-May-2005"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-25 21:41:05--  http://www.iro.umontreal.ca/~lisa/datasets/profiledata_06-May-2005.tar.gz\n",
            "Resolving www.iro.umontreal.ca (www.iro.umontreal.ca)... 132.204.26.36\n",
            "Connecting to www.iro.umontreal.ca (www.iro.umontreal.ca)|132.204.26.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 135880312 (130M) [application/x-gzip]\n",
            "Saving to: ‘profiledata_06-May-2005.tar.gz’\n",
            "\n",
            "profiledata_06-May- 100%[===================>] 129.58M  80.7MB/s    in 1.6s    \n",
            "\n",
            "2021-01-25 21:41:07 (80.7 MB/s) - ‘profiledata_06-May-2005.tar.gz’ saved [135880312/135880312]\n",
            "\n",
            "profiledata_06-May-2005/\n",
            "profiledata_06-May-2005/artist_data.txt\n",
            "profiledata_06-May-2005/README.txt\n",
            "profiledata_06-May-2005/user_artist_data.txt\n",
            "profiledata_06-May-2005/artist_alias.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW6KkGcugsZD",
        "outputId": "a72f1932-738e-48a8-ab14-dc05a19d80df"
      },
      "source": [
        "!cat dataset/user_artist_data.txt | head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000002 1 55\n",
            "1000002 1000006 33\n",
            "1000002 1000007 8\n",
            "1000002 1000009 144\n",
            "1000002 1000010 314\n",
            "1000002 1000013 8\n",
            "1000002 1000014 42\n",
            "1000002 1000017 69\n",
            "1000002 1000024 329\n",
            "1000002 1000025 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCekVANzgwyG"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import re\r\n",
        "import random\r\n",
        "from pyspark import SparkContext\r\n",
        "from pyspark.sql import SQLContext\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql import Row\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "sc =SparkContext.getOrCreate()\r\n",
        "sqlContext = SQLContext(sc)\r\n",
        "# Base directory path\r\n",
        "base = \"dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nttu1eAOhQVO"
      },
      "source": [
        "Using SPARK SQL, load data from /dataset/user_artist_data.txt and show the first 20 entries (via function show()).\r\n",
        "\r\n",
        "For this Notebook, from a programming point of view, we are given the schema for the data we use, which is as follows:\r\n",
        "\r\n",
        "userID: long int   \r\n",
        "artistID: long int   \r\n",
        "playCount: int   \r\n",
        "\r\n",
        "Each line of the dataset contains the above three fields, separated by a \"white space\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62B8ke_fg0Y1",
        "outputId": "f7fedfff-07f2-4b89-b68d-012098161b8b"
      },
      "source": [
        "userArtistDataSchema = StructType([ \\\r\n",
        "    StructField(\"userID\", LongType(), True), \\\r\n",
        "    StructField(\"artistID\", LongType(), True), \\\r\n",
        "    StructField(\"playCount\", IntegerType(), True)])\r\n",
        "\r\n",
        "userArtistDF = sqlContext.read \\\r\n",
        "    .format('com.databricks.spark.csv') \\\r\n",
        "    .options(header='false', delimiter=' ') \\\r\n",
        "    .load(base + \"user_artist_data.txt\", schema = userArtistDataSchema) \\\r\n",
        "    .cache()\r\n",
        "\r\n",
        "# we can cache an Dataframe to avoid computing it from the beginning everytime it is accessed.\r\n",
        "userArtistDF.cache()\r\n",
        "\r\n",
        "userArtistDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------+---------+\n",
            "| userID|artistID|playCount|\n",
            "+-------+--------+---------+\n",
            "|1000002|       1|       55|\n",
            "|1000002| 1000006|       33|\n",
            "|1000002| 1000007|        8|\n",
            "|1000002| 1000009|      144|\n",
            "|1000002| 1000010|      314|\n",
            "|1000002| 1000013|        8|\n",
            "|1000002| 1000014|       42|\n",
            "|1000002| 1000017|       69|\n",
            "|1000002| 1000024|      329|\n",
            "|1000002| 1000025|        1|\n",
            "|1000002| 1000028|       17|\n",
            "|1000002| 1000031|       47|\n",
            "|1000002| 1000033|       15|\n",
            "|1000002| 1000042|        1|\n",
            "|1000002| 1000045|        1|\n",
            "|1000002| 1000054|        2|\n",
            "|1000002| 1000055|       25|\n",
            "|1000002| 1000056|        4|\n",
            "|1000002| 1000059|        2|\n",
            "|1000002| 1000062|       71|\n",
            "+-------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJGNjwLPiBUU"
      },
      "source": [
        "**How many distinct users do we have in our data?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw6HcGdHho-Z",
        "outputId": "8bff72c4-5cc5-4420-bf82-f4a0493c5260"
      },
      "source": [
        "allusers = userArtistDF.count()\r\n",
        "print(\"All rows in database: \", allusers )\r\n",
        "uniqueUsers = userArtistDF.select('userID').distinct().count()\r\n",
        "print(\"Total n. of distinct users: \", uniqueUsers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All rows in database:  24296858\n",
            "Total n. of distinct users:  148111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gVFPgrKiKyv"
      },
      "source": [
        "**How many distinct artists do we have in our data ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvAWDd9qiE3N",
        "outputId": "47e7b58a-063b-4cef-e1ea-7ea05773284c"
      },
      "source": [
        "uniqueArtists = userArtistDF.select('artistID').distinct().count()\r\n",
        "print(\"Total n. of artists: \", uniqueArtists)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total n. of artists:  1631028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nybx6Zq2iXjB"
      },
      "source": [
        "**What are the maximum and minimum values of column userID ?**  \r\n",
        "One limitation of Spark MLlib's ALS implementation - which we will use later - is that it requires IDs for users and items to be nonnegative 32-bit integers. This means that IDs larger than Integer.MAX_VALUE, or 2147483647, can't be used. So we need to check whether this data set conforms to the strict requirements of our library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUL1DyBYiSlD",
        "outputId": "814e54f6-5eda-4451-f50c-4369e1a03cad"
      },
      "source": [
        "MAX_VALUE = 2147483647\r\n",
        "#showing the IDs which are invalid\r\n",
        "userArtistDF[(userArtistDF.userID.cast(\"int\") < 0)].show()\r\n",
        "userArtistDF[(userArtistDF.userID.cast(\"int\") > MAX_VALUE)].show()\r\n",
        "#As the result, we don't see any invalid userID\r\n",
        "#Otherwise, we can use function describe() of Spark MLlib to show the statistics\r\n",
        "userArtistDF.select(\"userID\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------+---------+\n",
            "|userID|artistID|playCount|\n",
            "+------+--------+---------+\n",
            "+------+--------+---------+\n",
            "\n",
            "+------+--------+---------+\n",
            "|userID|artistID|playCount|\n",
            "+------+--------+---------+\n",
            "+------+--------+---------+\n",
            "\n",
            "+-------+------------------+\n",
            "|summary|            userID|\n",
            "+-------+------------------+\n",
            "|  count|          24296858|\n",
            "|   mean|1947573.2653533637|\n",
            "| stddev| 496000.5551820078|\n",
            "|    min|                90|\n",
            "|    max|           2443548|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ4IEXxVise2"
      },
      "source": [
        "**What is the maximum and minimum values of column artistID ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYnZyiiAihbo",
        "outputId": "2b5bb2de-4d6c-477f-b7a2-7273db5d40ee"
      },
      "source": [
        "#Finding min and max of artistID using function groupby() and max|min()\r\n",
        "max_artistID = userArtistDF.groupby().max('artistID').collect()[0].asDict()['max(artistID)']\r\n",
        "print('Maximum value of artistID: ',max_artistID)\r\n",
        "min_artistID = userArtistDF.groupby().min('artistID').collect()[0].asDict()['min(artistID)']\r\n",
        "print('Minimum value of artistID: ',min_artistID)\r\n",
        "\r\n",
        "#Again, we can use describe() for short\r\n",
        "userArtistDF.select(\"artistID\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum value of artistID:  10794401\n",
            "Minimum value of artistID:  1\n",
            "+-------+------------------+\n",
            "|summary|          artistID|\n",
            "+-------+------------------+\n",
            "|  count|          24296858|\n",
            "|   mean|1718704.0937568964|\n",
            "| stddev|2539389.0924284607|\n",
            "|    min|                 1|\n",
            "|    max|          10794401|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QhxAjyzi5i-"
      },
      "source": [
        "We just discovered that we have a total of 148,111 users in our dataset. Similarly, we have a total of 1,631,028 artists in our dataset. The maximum values of userID and artistID are still smaller than the biggest number of integer type. No additional transformation will be necessary to use these IDs.\r\n",
        "\r\n",
        "One thing we can see here is that SPARK SQL provides very concise and powerful methods for data analytics (compared to using RDD and their low-level API). You can see more examples here.\r\n",
        "\r\n",
        "Next, we might want to understand better user activity and artist popularity.\r\n",
        "\r\n",
        "Here is a list of simple descriptive queries that helps us reaching these purposes:\r\n",
        "\r\n",
        "- How many times each user has played a song? This is a good indicator of who are the most active users of our service. Note that a very active user with many play counts does not necessarily mean that the user is also \"curious\"! Indeed, she could have played the same song several times.\r\n",
        "- How many play counts for each artist? This is a good indicator of the artist popularity. Since we do not have time information associated to our data, we can only build a, e.g., top-10 ranking of the most popular artists in the dataset. Later in the notebook, we will learn that our dataset has a very \"loose\" definition about artists: very often artist IDs point to song titles as well. This means we have to be careful when establishing popular artists. Indeed, artists whose data is \"well formed\" will have the correct number of play counts associated to them. Instead, artists that appear mixed with song titles may see their play counts \"diluted\" across their songs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyuKUbcTjZWz"
      },
      "source": [
        "**How many times each user has played a song? Display 5 samples of the result.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcU-nKLi-_h",
        "outputId": "175f9c81-17df-49c7-c127-97e3cc1c20e1"
      },
      "source": [
        "# We are interested in how many playcounts each user has scored.\r\n",
        "userActivity = userArtistDF.groupBy('userID').sum('playCount').collect()\r\n",
        "print(userActivity[0:5])\r\n",
        "len(userActivity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Row(userID=1000061, sum(playCount)=244), Row(userID=1000070, sum(playCount)=20200), Row(userID=1000313, sum(playCount)=201), Row(userID=1000832, sum(playCount)=1064), Row(userID=1000905, sum(playCount)=214)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ydAKJElXLw"
      },
      "source": [
        "**Plot CDF (or ECDF) of the number of play counts per User ID.**\r\n",
        "- Look at important percentiles (25%, median, 75%, tails such as >90%)\r\n",
        "- Discuss about users: we will notice that for some users, there is very little interaction with the system, which means that maybe reccommending something to them is going to be more difficult than for other users who interact more with the system.\r\n",
        "- Look at outliers and reasons about their impact on the reccommender algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "D6zDIZpQkxNo",
        "outputId": "f536c7ee-2160-46a7-8df1-41d7ec252fe4"
      },
      "source": [
        "pdf = pd.DataFrame(data=userActivity)\r\n",
        "Y=np.sort( pdf[1] )\r\n",
        "yvals=np.arange(len(Y))/float(len(Y))\r\n",
        "\r\n",
        "print(np.arange(len(Y)))\r\n",
        "\r\n",
        "plt.semilogx( Y, yvals )\r\n",
        "plt.xlabel('Play Counts')\r\n",
        "plt.ylabel('ECDF')\r\n",
        "plt.grid(True,which=\"both\",ls=\"-\")\r\n",
        "plt.title('ECDF of number of play counts per User ID')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#Morever, I would like to show some statistical measurements of userAcitvity\r\n",
        "print ('Total =', Y.sum())\r\n",
        "print ('Mean =', Y.mean())\r\n",
        "print ('Min =', Y.min())\r\n",
        "print ('Max =', Y.max())\r\n",
        "\r\n",
        "# look at important percentiles (25%, median, 75%, tails such as >90%)\r\n",
        "print('Percentile 25% :' + str(np.percentile(Y,25)))\r\n",
        "print('Percentile 50% :' + str(np.percentile(Y,50)))\r\n",
        "print('Percentile 75% :' + str(np.percentile(Y,75)))\r\n",
        "print('Percentile 90% :' + str(np.percentile(Y,90)))\r\n",
        "print('Percentile 95% :' + str(np.percentile(Y,95)))\r\n",
        "print('Percentile 99% :' + str(np.percentile(Y,99)))\r\n",
        "\r\n",
        "# look at the percentile has playCount less than 10\r\n",
        "print('The percentage of user playing less than 10 times P(Y<=10) =', len(Y[Y<=10])/len(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[     0      1      2 ... 148108 148109 148110]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Total = 371638969\n",
            "Mean = 2509.1922206993404\n",
            "Min = 1\n",
            "Max = 674412\n",
            "Percentile 25% :204.0\n",
            "Percentile 50% :892.0\n",
            "Percentile 75% :2800.0\n",
            "Percentile 90% :6484.0\n",
            "Percentile 95% :10120.0\n",
            "Percentile 99% :21569.199999999953\n",
            "The percentage of user playing less than 10 times P(Y<=10) = 0.05228511049145573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAyOfzhhmAnU"
      },
      "source": [
        "We have total 371638969 play counts.  \r\n",
        "In average, every user plays 2509 times.\r\n",
        "25% of the users have the play counts less than or equal to (<=) 204 times.  \r\n",
        "50% of the users have the play counts less than or equal to (<=) 892times.  \r\n",
        "75% of the users have the play counts less than or equal to (<=) 2800 times.  \r\n",
        "95% of the users have the play counts less than or equal to (<=) 10120 times.  \r\n",
        "99% of the users have the play counts less than or equal to (<=) 21569 times.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU1tjbgxnL2r"
      },
      "source": [
        "## The result is plausible with the figure above.\r\n",
        "About 7746 users (5.23%) have the play counts less than or equal to (<=) 10 times. These users have very little interaction with the system, so there is more difficult for recommending for these users than other users creating more impact in the system (have a certain number of playCount).¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP9wtc7jnflN"
      },
      "source": [
        "**How many play counts for each artist?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgtGJ8qelmeF",
        "outputId": "1e519d72-514b-417e-b0a3-bd05a3f6fa84"
      },
      "source": [
        "# Compute artist popularity\r\n",
        "# We are interested in how many playcounts per artist\r\n",
        "# ATTENTION! Grouping by artistID may be problematic, as stated above.\r\n",
        "\r\n",
        "artistPopularity = userArtistDF.groupBy('artistID').sum('playCount').collect()\r\n",
        "print(artistPopularity[0:5]) #print first 5 artistID in dataframe\r\n",
        "len(artistPopularity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Row(artistID=1003514, sum(playCount)=949), Row(artistID=1004346, sum(playCount)=3772), Row(artistID=5409, sum(playCount)=526693), Row(artistID=1002519, sum(playCount)=405), Row(artistID=1004223, sum(playCount)=409)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1631028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "6EuDLOXcnkZP",
        "outputId": "50df0757-ccc7-4d17-93d0-5c35eddcf2e5"
      },
      "source": [
        "pdf1 = pd.DataFrame(data=artistPopularity)\r\n",
        "Y1=np.sort( pdf1[1] )\r\n",
        "yvals1=np.arange(len(Y1))/float(len(Y1))\r\n",
        "\r\n",
        "print(np.arange(len(Y1)))\r\n",
        "\r\n",
        "plt.semilogx( Y1, yvals1 )\r\n",
        "plt.xlabel('Play Counts')\r\n",
        "plt.ylabel('ECDF')\r\n",
        "plt.grid(True,which=\"both\",ls=\"-\")\r\n",
        "plt.title('ECDF of number of play counts per artist ID')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#\r\n",
        "print ('Sum =', Y1.sum())\r\n",
        "print ('Mean =', Y1.mean())\r\n",
        "print ('Min =', Y1.min())\r\n",
        "print ('Max =', Y1.max())\r\n",
        "print ('Top 5 play counts:', Y1[len(Y1)-5:len(Y1)])\r\n",
        "print ('Sum top 5 artist play counts:', Y1[len(Y1)-5:len(Y1)].sum())\r\n",
        "print ('Percentage of top 5 artist play counts:', Y1[len(Y1)-5:len(Y1)].sum()/Y1.sum())\r\n",
        "print ('P(playCount<=10) =', len(Y1[Y1<=10])/len(Y1))\r\n",
        "print ('P(playCount<=1000) =', len(Y1[Y1<=1000])/len(Y1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[      0       1       2 ... 1631025 1631026 1631027]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Sum = 371638969\n",
            "Mean = 227.85566464830768\n",
            "Min = 1\n",
            "Max = 2502130\n",
            "Top 5 play counts: [1425942 1542806 1930592 2259185 2502130]\n",
            "Sum top 5 artist play counts: 9660655\n",
            "Percentage of top 5 artist play counts: 0.025994730923925256\n",
            "P(playCount<=10) = 0.7486793605014751\n",
            "P(playCount<=1000) = 0.987435531456235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2IDKcFonzcV"
      },
      "source": [
        "**Answer :**  \r\n",
        "**Total 371638969 play counts. In average, playCount per artist is 227 times**  \r\n",
        "**Only 74.87% of the artists is played less than or equal to (<=) 10 times.**  \r\n",
        "**And 98.74% of the artists is played less than or equal to (<=) 1000 times.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDDMnEToB5_"
      },
      "source": [
        "**In the other hand, we have top 5 artist play counts: [1425942 1542806 1930592 2259185 2502130]. This accounts for 2.6% on overall number of playCount (5 out of 1631028 artists). Moreover, the play count of top 5 artist is much higher than the mean. So we can implie that we can recommend most-played artists to every user with this top 5 artirst, and still get high performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SvfwSiBoGv1"
      },
      "source": [
        "**Plot a bar chart to show top 5 artists In terms of absolute play counts.**\r\n",
        "- Are these reasonable results?\r\n",
        "- Looking at top-5 artists\r\n",
        "- Anything strange in the data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "02w2D2font7L",
        "outputId": "a0a9be9c-d85b-4d2b-f7d0-9ab71cc3efc8"
      },
      "source": [
        "sortedArtist = sorted(artistPopularity, key = lambda x: -x[1])[:5]\r\n",
        "\r\n",
        "artistID = [w[0] for w in sortedArtist]\r\n",
        "\r\n",
        "y_pos = range(len(sortedArtist))\r\n",
        "frequency = [w[1] for w in sortedArtist]\r\n",
        "\r\n",
        "plt.barh(y_pos, frequency[::-1], align='center', alpha=0.4)\r\n",
        "plt.yticks(y_pos, artistID[::-1])\r\n",
        "plt.xlabel('Play Count')\r\n",
        "plt.ylabel('Artist')\r\n",
        "plt.title('Top-5 Artist ID per play counts')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQOzJrrcoei7"
      },
      "source": [
        "## Answer: \r\n",
        "\r\n",
        "**This results seem not reasonable.**    \r\n",
        "\r\n",
        "**In the previous, 98.74% of the artists have the play count less than or equal to (<=) 1000 times. So, top-5-artists is not sufficient to extract infomation about the data, they are the outliers . We should cut them out of data.**\r\n",
        "\r\n",
        "**As the result, top-5-artists take about 2.6% of the total play counts, but 98.74% of the artists have the play count less than or equal to (<=) 1000 times. Then this is obviously that some artists are played much more than other artists.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNH5hKp4o8C3"
      },
      "source": [
        "All seems clear right now, but ... wait a second! What about the problems indicated above about artist \"disambiguation\"? Are these artist ID we are using referring to unique artists? How can we make sure that such \"opaque\" identifiers point to different bands? Let's try to use some additional dataset to answer this question: artist_data.txt dataset. This time, the schema of the dataset consists in:  \r\n",
        "\r\n",
        "artist ID: long int  \r\n",
        "name: string  \r\n",
        "\r\n",
        "We will try to find whether a single artist has two different IDs.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HW3CWQOpCu1"
      },
      "source": [
        "## Data Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TPww_h6pHle"
      },
      "source": [
        "**Loading artist data**  \r\n",
        "Load the data from / dataset/artist_data.txt and use the SparkSQL API to show 5 samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPX_RFpuoUCH",
        "outputId": "994651fe-a905-42de-b6c3-cd4cd06a35d8"
      },
      "source": [
        "customSchemaArtist = StructType([ \\\r\n",
        "    StructField(\"artistID\", LongType(), True), \\\r\n",
        "    StructField(\"name\", StringType(), True)])\r\n",
        "\r\n",
        "artistDF = sqlContext.read \\\r\n",
        "    .format('com.databricks.spark.csv') \\\r\n",
        "    .options(header='false', delimiter='\\t', mode='DROPMALFORMED') \\\r\n",
        "    .load(base + \"artist_data.txt\", schema = customSchemaArtist) \\\r\n",
        "    .cache()\r\n",
        "artistDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|artistID|                name|\n",
            "+--------+--------------------+\n",
            "| 1134999|        06Crazy Life|\n",
            "| 6821360|        Pang Nakarin|\n",
            "|10113088|Terfel, Bartoli- ...|\n",
            "|10151459| The Flaming Sidebur|\n",
            "| 6826647|   Bodenstandig 3000|\n",
            "+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cgUxE0npfAw"
      },
      "source": [
        "Look at top 20 artists whose name contains \"Aerosmith\". Take a look at artists that have ID equal to 1000010 and 2082323. Are they pointing to the same artist?\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ4Tq1WRpjPJ"
      },
      "source": [
        "HINT: Function locate(sub_string, string) can be useful in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DWmjk4hpdu9",
        "outputId": "76b07e4a-3380-4d96-96a0-ea9249c0a589"
      },
      "source": [
        "# get artists whose name contains \"Aerosmith\"\r\n",
        "artistDF[locate(\"Aerosmith\", artistDF.name) > 0].show(20, False)\r\n",
        "\r\n",
        "# show two examples\r\n",
        "artistDF[artistDF.artistID==1000010].show()\r\n",
        "artistDF[artistDF.artistID==2082323].show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----------------------------------------------+\n",
            "|artistID|name                                          |\n",
            "+--------+----------------------------------------------+\n",
            "|10586006|Dusty Springfield/Aerosmith                   |\n",
            "|6946007 |Aerosmith/RunDMC                              |\n",
            "|10475683|Aerosmith: Just Push Play                     |\n",
            "|1083031 |Aerosmith/ G n R                              |\n",
            "|6872848 |Britney, Nsync, Nelly, Aerosmith,Mary J Blige.|\n",
            "|10586963|Green Day - Oasis - Eminem - Aerosmith        |\n",
            "|10028830|The Aerosmith Antology2                       |\n",
            "|10300357|Run-DMC + Aerosmith                           |\n",
            "|2027746 |Aerosmith by MusicInter.com                   |\n",
            "|1140418 |[rap]Run DMC and Aerosmith                    |\n",
            "|10237208|Aerosmith + Run DMC                           |\n",
            "|10588537|Aerosmith, Kid Rock, & Run DMC                |\n",
            "|9934757 |Aerosmith - Big Ones                          |\n",
            "|10437510|Green Day ft. Oasis & Aerosmith               |\n",
            "|6936680 |RUN DNC & Aerosmith                           |\n",
            "|10479781|Aerosmith Hits                                |\n",
            "|10114147|Charlies Angels - Aerosmith                   |\n",
            "|1262439 |Kid Rock, Run DMC & Aerosmith                 |\n",
            "|7032554 |Aerosmith & Run-D.M.C.                        |\n",
            "|10033592|Aerosmith?                                    |\n",
            "+--------+----------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+---------+\n",
            "|artistID|     name|\n",
            "+--------+---------+\n",
            "| 1000010|Aerosmith|\n",
            "+--------+---------+\n",
            "\n",
            "+--------+------------+\n",
            "|artistID|        name|\n",
            "+--------+------------+\n",
            "| 2082323|01 Aerosmith|\n",
            "+--------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgLiVEpspwvS"
      },
      "source": [
        "In my opinion, they are pointing to the same artist\r\n",
        "To answer this question correctly, we need to use an additional dataset artist_alias.txt which contains the ids of mispelled artists and standard artists. The schema of the dataset consists in:  \r\n",
        "\r\n",
        "mispelledID ID: long int  \r\n",
        "standard ID: long int  \r\n",
        "\r\n",
        "Using SparkSQL API, load the dataset from /dataset/artist_alias.txt then show 5 samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd0fi7uOpvzz",
        "outputId": "d1e647b8-7619-48a4-8a3f-a3676e3fbc48"
      },
      "source": [
        "customSchemaArtistAlias = StructType([ \\\r\n",
        "    StructField(\"mispelledID\", LongType(), True), \\\r\n",
        "    StructField(\"standardID\", LongType(), True)])\r\n",
        "\r\n",
        "artistAliasDF = sqlContext.read \\\r\n",
        "    .format('com.databricks.spark.csv') \\\r\n",
        "    .options(header='false', delimiter='\\t', mode='DROPMALFORMED') \\\r\n",
        "    .load(base + \"artist_alias.txt\", schema = customSchemaArtistAlias) \\\r\n",
        "    .cache()\r\n",
        "\r\n",
        "artistAliasDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------+\n",
            "|mispelledID|standardID|\n",
            "+-----------+----------+\n",
            "|    1092764|   1000311|\n",
            "|    1095122|   1000557|\n",
            "|    6708070|   1007267|\n",
            "|   10088054|   1042317|\n",
            "|    1195917|   1042317|\n",
            "+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrHEjkgnqN3B"
      },
      "source": [
        "**Verify the answer of \"Are artists that have ID equal to 1000010 and 2082323 the same ?\" by finding the standard ids corresponding to the mispelled ids 1000010 and 2082323 respectively.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3kWa4PpX1l",
        "outputId": "b0ec8d45-ea9b-43ef-a677-99f14ea6ca0a"
      },
      "source": [
        "artistAliasDF[artistAliasDF.mispelledID == \"1000010\" ].show()\r\n",
        "artistAliasDF[artistAliasDF.mispelledID == \"2082323\" ].show()\r\n",
        "\r\n",
        "# 1000010 is a standard id, so it haven't been considered as mispelled id in the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------+\n",
            "|mispelledID|standardID|\n",
            "+-----------+----------+\n",
            "+-----------+----------+\n",
            "\n",
            "+-----------+----------+\n",
            "|mispelledID|standardID|\n",
            "+-----------+----------+\n",
            "|    2082323|   1000010|\n",
            "+-----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiltIEQWqbTm"
      },
      "source": [
        "**After evaluating mispelledID, my guess is correct because the artistID = \"2082323\" has standardID=\"1000010\", which means representing the same artist**  \r\n",
        "The mispelled or nonstandard information about artist make our results in the previous queries a bit \"sloppy\". To overcome this problem, we can replace all mispelled artist ids by the corresponding standard ids and re-compute the basic descriptive statistics on the \"amended\" data. First, we construct a \"dictionary\" that maps non-standard ids to a standard ones. Then this \"dictionary\" will be used to replace the mispelled artists.  \r\n",
        "\r\n",
        "\r\n",
        "From data in the dataframe loaded from / dataset/artist_alias.txt, construct a dictionary that maps each non-standard id to its standard id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Fr2wA-qaMU",
        "outputId": "2bb42473-e65a-42e7-9de8-4aff3ae2767e"
      },
      "source": [
        "artistAlias = artistAliasDF.rdd.map(lambda row: (row.mispelledID,row.standardID)).collectAsMap()\r\n",
        "\r\n",
        "#checking the total number of standard artistID\r\n",
        "len(artistAlias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfcZjc7Iqozq"
      },
      "source": [
        "**The total number row of the dictionary now 190893 artists. This gives me the lesson that we should standalize the field of the data which more likely to create ambiguity**  \r\n",
        "\r\n",
        "Using the constructed dictionary artistAlias, replace the non-standard artist ids in the dataframe that was loaded from / dataset/user_artist_data.txt by the corresponding standard ids then show 5 samples.\r\n",
        "\r\n",
        "**NOTE:** If an id doesn't exist in the dictionary as a mispelled id, it is really a standard id.\r\n",
        "\r\n",
        "Using funtion map on Spark Dataframe will give us an RDD. We can convert this RDD back to Dataframe by using sqlContext.createDataFrame(rdd_name, sql_schema)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT3-dcX8qZGN",
        "outputId": "14f322f4-b089-4901-8bf3-c715e216af42"
      },
      "source": [
        "from time import time\r\n",
        "\r\n",
        "bArtistAlias = sc.broadcast(artistAlias)\r\n",
        "\r\n",
        "def replaceMispelledIDs(fields):\r\n",
        "    finalID = bArtistAlias.value.get(fields[1] ,fields[1])\r\n",
        "    return (fields[0], finalID, fields[2])\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "newUserArtistDF = sqlContext.createDataFrame(\r\n",
        "    userArtistDF.rdd.map(replaceMispelledIDs), \r\n",
        "    userArtistDataSchema\r\n",
        ")\r\n",
        "newUserArtistDF.show(5)\r\n",
        "t1 = time()\r\n",
        "\r\n",
        "print('The script takes %f seconds' %(t1-t0))\r\n",
        "newUserArtistDF = newUserArtistDF.cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------+---------+\n",
            "| userID|artistID|playCount|\n",
            "+-------+--------+---------+\n",
            "|1000002|       1|       55|\n",
            "|1000002| 1000006|       33|\n",
            "|1000002| 1000007|        8|\n",
            "|1000002| 1000009|      144|\n",
            "|1000002| 1000010|      314|\n",
            "+-------+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The script takes 0.759941 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhA7IeCiq6z-"
      },
      "source": [
        "Although having some advantages, explicitly creating broadcast variables is only useful when tasks across multiple stages need the same data or when caching the data in deserialized form is important.\r\n",
        "\r\n",
        "Well, our data frame contains clean and \"standard\" data. We can use it to redo previous statistic queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD-_6T0ZrE9h"
      },
      "source": [
        "**How many unique artists? Compare with the result when using old data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP0cVlLBrEK6",
        "outputId": "a954c7da-d7f1-444a-cebb-a1bff7a36ae9"
      },
      "source": [
        "uniqueArtists = newUserArtistDF.select('artistID').distinct().count()\r\n",
        "\r\n",
        "print(\"Total n. of artists: \", uniqueArtists)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total n. of artists:  1568126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBWO4F6IrTsu"
      },
      "source": [
        "**The number of artists is reduced (from 1631028 to 1568126) after cleaning and standardization (replacing mispelledID with standardID).**  \r\n",
        "Who are the top-10 artistis?  \r\n",
        "- In terms of absolute play counts\r\n",
        "- In terms of \"audience size\", that is, how many users listened to one of their track at least once.  \r\n",
        "\r\n",
        "Plot the results, and explain the figures you obtain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Px8NcU4Pq0zX",
        "outputId": "6374b70a-c5a4-4847-86a8-da64751af09b"
      },
      "source": [
        "# calculate top-10 artists in term of play counts\r\n",
        "top10ArtistsPC = newUserArtistDF.groupBy('artistID').sum('playCount').orderBy('sum(playCount)', ascending=0).take(10)\r\n",
        "\r\n",
        "y_pos = list(range(len(top10ArtistsPC)))\r\n",
        "pdf = pd.DataFrame(data=top10ArtistsPC)\r\n",
        "\r\n",
        "plt.barh(y_pos, pdf[1][::-1], align='center', alpha=0.4)\r\n",
        "plt.yticks(y_pos, pdf[0][::-1])\r\n",
        "plt.xlabel('Play Count')\r\n",
        "plt.ylabel('Artist')\r\n",
        "plt.title('Top-10 Artist ID per play counts')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl78hyljrt8o"
      },
      "source": [
        "**After removing all mispelledID, there is little increase in playCounts of top-10-artists.**   \r\n",
        "**Here I show the comparison on playCount of top 10 artist before and after removing mispelledID**  \r\n",
        "**artistID=979: 2502130 -> 2502596.**  \r\n",
        "**artistID=1000113: 2259185 -> 2259825.**  \r\n",
        "**artistID=4267: 1930592 -> 1931143.**  \r\n",
        "**artistID=1000024: 1542806 -> 1543430.**   \r\n",
        "**artistID=4468: 1425942 -> 1426254.**  \r\n",
        "**artistID=82: 1399418 -> 1399665.**  \r\n",
        "**artistID=831: 1361392 -> 1361977.**  \r\n",
        "**artistID=1001779: 1328869 -> 1328969.**  \r\n",
        "**artistID=1000130: 1234387 -> 1234773.**  \r\n",
        "**artistID=976: 1203226 -> 1203348.**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9vgyFMVsHrn"
      },
      "source": [
        "**The chart shows that playCount dramatiaclly decreases from the 1st artist to the 4th artist in top-10-artists, but from the 4th artist to 10th artist, it decreases slightly.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQo2j6-asOsc"
      },
      "source": [
        "**Who are the top-10 users?**\r\n",
        "- In terms of absolute play counts\r\n",
        "- In terms of \"curiosity\", that is, how many different artists they listened to.\r\n",
        "\r\n",
        "\r\n",
        "Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "igwtwrfzrjqj",
        "outputId": "7604a611-6775-43ff-bb7c-ab866ea8be86"
      },
      "source": [
        "# calculate top 10 users in term of play counts\r\n",
        "top10UsersByPlayCount = newUserArtistDF.groupBy(\"userID\").sum('playCount').orderBy('sum(playCount)', ascending=0).take(10)\r\n",
        "\r\n",
        "y_pos = list(range(len(top10UsersByPlayCount)))\r\n",
        "pdf = pd.DataFrame(data=top10UsersByPlayCount)\r\n",
        "\r\n",
        "plt.barh(y_pos, pdf[1][::-1], align='center', alpha=0.4)\r\n",
        "plt.yticks(y_pos, pdf[0][::-1])\r\n",
        "plt.xlabel('Play Count') \r\n",
        "plt.ylabel('User')\r\n",
        "plt.title('Top-10 Users ID per play counts')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Hsn5Mv27sUmb",
        "outputId": "1fe5b90d-686d-4627-df15-ddca2f7472d7"
      },
      "source": [
        "top10UsersByCuriosity = (newUserArtistDF.dropDuplicates(['userID', 'artistID'])\r\n",
        "                             .groupBy(\"userID\")\r\n",
        "                             .count()\r\n",
        "                             .orderBy('count', ascending=0)\r\n",
        "                             .take(10)\r\n",
        "                         )\r\n",
        "\r\n",
        "#print(top10UsersByCuriosity)\r\n",
        "y_pos = range(len(top10UsersByCuriosity))\r\n",
        "\r\n",
        "pdf = pd.DataFrame(data=top10UsersByCuriosity)\r\n",
        "\r\n",
        "plt.barh(y_pos, pdf[1][::-1], align='center', alpha=0.4)\r\n",
        "plt.yticks(y_pos, pdf[0][::-1])\r\n",
        "plt.xlabel('Number of played artists')\r\n",
        "plt.ylabel('User')\r\n",
        "plt.title('Top-10 Users ID per Curiosity')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC7BTstssu81"
      },
      "source": [
        "# Build a statistical models to make recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjsaukD-JBx8"
      },
      "source": [
        "# Introduction to recommender systems\r\n",
        "In a recommendation-system application there are two classes of entities, which we shall refer to as users and items. Users have preferences for certain items, and these preferences must be inferred from the data. The data itself is represented as a preference matrix $A$, giving for each user-item pair, a value that represents what is known about the degree of preference of that user for that item. The table below is an example for a preference matrix of 5 users and k items. The preference matrix is also known as utility matrix.  \r\n",
        "IT1 |\tIT2 |\tIT3\t| ...\t| ITk  \r\n",
        "---| --- | --- | --- | ---\r\n",
        "U1\t1\t...\t5\t...\t3\r\n",
        "U2\t...\t2\t...\t...\t2\r\n",
        "U3\t5\t...\t3\t...\t...\r\n",
        "U4\t3\t3\t...\t...\t4\r\n",
        "U5\t...\t1\t...\t...\t.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPk9aTqgJpHP"
      },
      "source": [
        "\\ | IT1 |\tIT2 |\tIT3\t| ...\t| ITk  \r\n",
        "--- | --- | --- | --- | ---| ---\r\n",
        "U1 | 1\t| ...\t| 5\t| ...\t| 3\r\n",
        "U2 |...\t| 2\t| ...\t| ...\t| 2\r\n",
        "U3 | 5\t|...\t|3\t| ...\t| ...\r\n",
        "U4 |3\t | 3| ...\t| ...\t| 4\r\n",
        "U5 |... |\t1\t| ...\t| ... |\t..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC4j6Xa4KjcZ"
      },
      "source": [
        "The value of row i, column j expresses how much does user i like item j. The values are often the rating scores of users for items. An unknown value implies that we have no explicit information about the user's preference for the item. The goal of a recommendation system is to predict \"the blanks\" in the preference matrix. For example, assume that the rating score is from 1 (dislike) to 5 (love), would user U5 like IT3 ? We have two approaches:\r\n",
        "\r\n",
        "- Designing our recommendation system to take into account properties of items such as brand, category, price... or even the similarity of their names. We can denote the similarity of items IT2 and IT3, and then conclude that because user U5 did not like IT2, they were unlikely to enjoy SW2 either.\r\n",
        "\r\n",
        "- We might observe that the people who rated both IT2 and IT3 tended to give them similar ratings. Thus, we could conclude that user U5 would also give IT3 a low rating, similar to U5's rating of IT2\r\n",
        "\r\n",
        "It is not necessary to predict every blank entry in a utility matrix. Rather, it is only necessary to discover some entries in each row that are likely to be high. In most applications, the recommendation system does not oﬀer users a ranking of all items, but rather suggests a few that the user should value highly. It may not even be necessary to ﬁnd all items with the highest expected ratings, but only to ﬁnd a large subset of those with the highest ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi6pQ7NdKog9"
      },
      "source": [
        "# Families of recommender systems\r\n",
        "In general, recommender systems can be categorized into two groups:\r\n",
        "\r\n",
        "- **Content-Based systems** focus on properties of items. Similarity of items is determined by measuring the similarity in their properties.\r\n",
        "\r\n",
        "- **Collaborative-Filtering** systems focus on the relationship between users and items. Similarity of items is determined by the similarity of the ratings of those items by the users who have rated both items.\r\n",
        "\r\n",
        "In the usecase of this notebook, artists take the role of items, and users keep the same role as users. Since we have no information about artists, except their names, we cannot build a content-based recommender system.\r\n",
        "\r\n",
        "Therefore, in the rest of this notebook, we only focus on Collaborative-Filtering algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV48jYy0LK9S"
      },
      "source": [
        "# **Collaborative-Filtering**\r\n",
        "In this section, we study a member of a broad class of algorithms called latent-factor models. They try to explain observed interactions between large numbers of users and products through a relatively small number of unobserved, underlying reasons. It is analogous to explaining why millions of people buy a particular few of thousands of possible albums by describing users and albums in terms of tastes for perhaps tens of genres, tastes which are **not directly observable or given** as data.\r\n",
        "\r\n",
        "First, we formulate the learning problem as a matrix completion problem. Then, we will use a type of matrix factorization model to \"fill in\" the blanks. We are given implicit ratings that users have given certain items (that is, the number of times they played a particular artist) and our goal is to predict their ratings for the rest of the items. Formally, if there are $n$ users and $m$ items, we are given an $n \\times m$ matrix $R$ in which the generic entry $(u, i)$ represents the rating for item $i$ by user $u$. **Matrix $R$ has many missing entries indicating unobserved ratings, and our task is to estimate these unobserved ratings.**\r\n",
        "\r\n",
        "A popular approach to the matrix completion problem is **matrix factorization**, where we want to \"summarize\" users and items with their **latent factors**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh8St9sWLZ6a"
      },
      "source": [
        "## Parallel Altenating Least Squares using broadcast variables\r\n",
        "\r\n",
        "The approach takes advantage of the fact that the $X$ and $Y$ factor matrices are often very small and can be stored locally on each machine.\r\n",
        "\r\n",
        "- Partition the Ratings RDD by user to create $R_1$, and similarly partition the Ratings RDD by item to create $R_2$. This means there are two copies of the same Ratings RDD, albeit with different partitionings. In $R_1$, all ratings by the same user are on the same machine, and in $R_2$ all ratings for same item are on the same machine.\r\n",
        "- Broadcast the matrices $X$ and $Y$. Note that these matrices are not RDD of vectors: they are now \"local: matrices.\r\n",
        "- Using $R_1$ and $Y$, we can use expression $x_u$ from above to compute the update of $x_u$ locally on each machine\r\n",
        "- Using $R_2$ and $X$, we can use expression $y_i$ from above to compute the update of $y_i$ locally on each machine  \r\n",
        "\r\n",
        "A further optimization to this method is to group the $X$ and $Y$ factors matrices into blocks (user blocks and item blocks) and reduce the communication by only sending to each machine the block of users (or items) that are needed to compute the updates at that machine.\r\n",
        "\r\n",
        "This method is called Block ALS. It is achieved by precomputing some information about the ratings matrix to determine the \"out-links\" of each user (which blocks of the items it will contribute to) and \"in-link\" information for each item (which of the factor vectors it receives from each user block it will depend on). For exmple, assume that machine 1 is responsible for users 1,2,...,37: these will be block 1 of users. The items rated by these users are block 1 of items. Only the factors of block 1 of users and block 1 of items will be broadcasted to machine 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBIiQhHLrAc"
      },
      "source": [
        "## Further readings\r\n",
        "Other methods for matrix factorization include:\r\n",
        "\r\n",
        "- Low Rank Approximation and Regression in Input Sparsity Time, by Kenneth L. Clarkson, David P. Woodruff. http://arxiv.org/abs/1207.6365\r\n",
        "Generalized Low Rank Models (GLRM), by Madeleine Udell, Corinne Horn, Reza Zadeh, Stephen Boyd. http://arxiv.org/abs/1410.0342\r\n",
        "- Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares, by Trevor Hastie, Rahul Mazumder, Jason D. Lee, Reza Zadeh . Statistics Department and ICME, Stanford University, 2014. http://stanford.edu/~rezab/papers/fastals.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wqG-54CL69E"
      },
      "source": [
        "# Music recommender system\r\n",
        "In this usecase, we use the data of users and artists in the previous sections to build a statistical model to recommend artists for users.\r\n",
        "\r\n",
        "## Requirements\r\n",
        "According to the properties of data, we need to choose a recommender algorithm that is suitable for this implicit feedback data. It means that the algorithm should learn without access to user or artist attributes such as age, genre,.... Therefore, an algorithm of type collaborative filtering is the best choice.\r\n",
        "\r\n",
        "Second, in the data, there are some users that have listened to only 1 artist. We need an algorithm that might provide decent recommendations to even these users. After all, at some point, every user starts out with just one play at some point!\r\n",
        "\r\n",
        "Third, we need an algorithm that scales, both in its ability to build large models, and to create recommendations quickly. So, an algorithm which can run on a distributed system (SPARK, Hadoop...) is very suitable.\r\n",
        "\r\n",
        "From these requirement, we can choose using ALS algorithm in SPARK's MLLIB.\r\n",
        "\r\n",
        "Spark MLlib’s ALS implementation draws on ideas from 1 and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIgNEQWhL-eC"
      },
      "source": [
        "# Notes\r\n",
        "Currently, MLLIB can only build models from an RDD. That means we have two ways to prepare data:\r\n",
        "\r\n",
        "- Loading to into SPARK SQL DataFrame as before, and then access the corresponding RDD by calling <dataframe>.rdd. The invalid data is often sucessfully dropped by using mode DROPMALFORMED. However, this way might not work in all cases. Fortunately, we can use it with this usecase.\r\n",
        "\r\n",
        "- Loading data directly to RDD. However, we have to deal with the invalid data ourself. In the trade-off, this way is the most reliable, and can work in every case.\r\n",
        "\r\n",
        "In this notebook, we will use the second approach: it requires a bit more effort, but the reward is worth it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgBNF5w_MFpL"
      },
      "source": [
        "## Cleanup the data\r\n",
        "In section Data Integration, I already replaced the ids of mispelled artist IDs by the corresponding standard ids by using SPARK SQL API. However, if the data has the invalid entries such that SPARK SQL API is stuck, the best way to work with it is using an RDD.\r\n",
        "\r\n",
        "Just as a recall, I work with three datasets in user_artist_data.txt, ` andartist_alias.txt`. The entries in these file can be empty or have only one field.\r\n",
        "\r\n",
        "In details our goal now is:\r\n",
        "\r\n",
        "- Read the input user_artist_data.txt and transforms its representation into an output dataset.\r\n",
        "To produce an output \"tuple\" containing the original user identifier and play counts, but with the artist identifier replaced by its most common alias, as found in the artist_alias.txt dataset.\r\n",
        "- Since the artist_alias.txt file is small, we can use a technique called broadcast variables to make such transformation more efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcOllL_cMO85"
      },
      "source": [
        "## Load data from /dataset/artist_alias.txt and filter out the invalid entries to construct a dictionary to map from mispelled artists' ids to standard ids.\r\n",
        "NOTE:\r\n",
        "\r\n",
        "- From now on, we will use the \"standard\" data to train our model.\r\n",
        "- If a line contains less than 2 fields or contains invalid numerial values, we can return a special tuple. After that, we can filter out these special tup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkOftWyhsk5Y"
      },
      "source": [
        "rawArtistAlias = sc.textFile(base + \"artist_alias.txt\")\r\n",
        "\r\n",
        "def xtractFields(s):\r\n",
        "    # Using white space or tab character as separetors,\r\n",
        "    # split a line into list of strings \r\n",
        "    line = re.split(\"\\s|\\t\",s,1)\r\n",
        "    # if this line has at least 2 characters\r\n",
        "    if (len(line) > 1):\r\n",
        "        try:\r\n",
        "            # try to parse the first and the second components to integer type\r\n",
        "            return (int(line[0]), int(line[1]))\r\n",
        "        except ValueError:\r\n",
        "            # if parsing has any error, return a special tuple\r\n",
        "            return (-1,-1)\r\n",
        "    else:\r\n",
        "        # if this line has less than 2 characters, return a special tuple\r\n",
        "        return (-1,-1)\r\n",
        "\r\n",
        "artistAlias = (\r\n",
        "                rawArtistAlias\r\n",
        "                    # extract fields using function xtractFields\r\n",
        "                    .map( lambda x: xtractFields(x))\r\n",
        "\r\n",
        "                    # fileter out the special tuples\r\n",
        "                    .filter( lambda x: x != (-1,-1) )\r\n",
        "                    # collect result to the driver as a \"dictionary\"\r\n",
        "                    .collectAsMap()\r\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiUqmbvrMYp1"
      },
      "source": [
        "**Prepare RDD userArtistDataRDD by replacing mispelled artists' ids to standard ids. Show 5 samples.**\r\n",
        "Using broadcast varible can help us increase the effiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKZVQrRAMWb7",
        "outputId": "b5bdfa4f-6064-4c12-bfd0-e15957e8c41c"
      },
      "source": [
        "bArtistAlias = sc.broadcast(artistAlias)\r\n",
        "rawUserArtistData = sc.textFile(base + \"user_artist_data.txt\")\r\n",
        "\r\n",
        "def disambiguate(line):\r\n",
        "    [userID, artistID, count] = line.split(' ')\r\n",
        "    finalArtistID = bArtistAlias.value.get(artistID,artistID)\r\n",
        "    return (userID, finalArtistID,count)\r\n",
        "\r\n",
        "\r\n",
        "userArtistDataRDD = rawUserArtistData.map(disambiguate)\r\n",
        "userArtistDataRDD.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1000002', '1', '55'),\n",
              " ('1000002', '1000006', '33'),\n",
              " ('1000002', '1000007', '8'),\n",
              " ('1000002', '1000009', '144'),\n",
              " ('1000002', '1000010', '314')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxKjga9qMfJd"
      },
      "source": [
        "## Training our statistical model\r\n",
        "To train a model using ALS, we must use a preference matrix as an input. MLLIB uses the class Rating to support the construction of a distributed preference matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJyfqupMMkch"
      },
      "source": [
        "**Given RDD userArtistDataRDD in previous section, construct a new RDD called trainingData by tranforming each item of it into a Rating object.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tAy7jzpMdAe"
      },
      "source": [
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pieq2T96MnaY",
        "outputId": "3907503c-407d-4e5c-d45d-99aa30a76888"
      },
      "source": [
        "allData = userArtistDataRDD.map(lambda r: Rating( float(r[0]),float(r[1]),int(r[2]))) \\\r\n",
        "                                            .repartition(12).cache()\r\n",
        "allData.take(5)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Rating(user=1000002, product=1001008, rating=151.0),\n",
              " Rating(user=1000002, product=1001065, rating=1.0),\n",
              " Rating(user=1000002, product=1001129, rating=23.0),\n",
              " Rating(user=1000002, product=1001130, rating=3.0),\n",
              " Rating(user=1000002, product=1001152, rating=2.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GhyH0DSMp3V"
      },
      "source": [
        "**A model can be trained by using ALS.trainImplicit(<training data>, <rank>), where:**\r\n",
        "- training data is the input data you decide to feed to the ALS algorithm\r\n",
        "- rank is the number of laten features\r\n",
        "We can also use some additional parameters to adjust the quality of the model. Currently, let's set\r\n",
        "\r\n",
        "- rank=10\r\n",
        "- iterations=5\r\n",
        "- lambda_=0.01\r\n",
        "- alpha=1.0  \r\n",
        "\r\n",
        "to build model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45txR3tMpOh",
        "outputId": "767c2a4f-ca7a-46e2-e5cd-af0f7fbbac82"
      },
      "source": [
        "#setting parameters\r\n",
        "rank=10\r\n",
        "iterations=5\r\n",
        "lambda_=0.01\r\n",
        "alpha=1.0\r\n",
        "\r\n",
        "#training\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(allData, rank)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish training model in 275.638808 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nGEmp_4M7J1"
      },
      "source": [
        "**The trained model can be saved into HDFS for later use. This can be done via model.save(sc, < file_name >).**  \r\n",
        "Let's use this function to store our model as name music_rec_model.spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFRSMOCiM5IT",
        "outputId": "9edd8d6e-cb81-4d24-ace8-7ee57a998101"
      },
      "source": [
        "#! hdfs dfs -rm -R -f -skipTrash lastfm_model.spark\r\n",
        "#print('Delete old model')\r\n",
        "model.save(sc,'music_rec_model.spark')\r\n",
        "print('Save new model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save new model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0rnBlwENKZl"
      },
      "source": [
        "**A saved model can be load from file by using MatrixFactorizationModel.load(sc, < file_name >).**\r\n",
        "Let's load the saved model from file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwcV5iF4NE1p",
        "outputId": "37ea56d0-d2cc-40ec-b7a1-01a560da9963"
      },
      "source": [
        "t0 = time()\r\n",
        "model = MatrixFactorizationModel.load(sc, 'music_rec_model.spark')\r\n",
        "t1 = time()\r\n",
        "print(\"finish loading model in %f secs\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish loading model in 0.995133 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARt-2oogNR_r"
      },
      "source": [
        "**Print the first row of user features in our model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CohwZQPrNPq1",
        "outputId": "453ea637-5fa7-419a-a777-dc50edcd068d"
      },
      "source": [
        "model.userFeatures().first()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90,\n",
              " array('d', [-0.021951021626591682, -0.042128026485443115, -0.00309071596711874, 0.07067042589187622, 0.01921253837645054, 0.03545057028532028, 0.045839905738830566, -0.0635233074426651, -0.023421017453074455, -0.061388690024614334]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l3yVgNGNV8B"
      },
      "source": [
        "**Show the top-5 artist names recommendated for user 2093760.**  \r\n",
        "The recommendations can be given by function recommendProducts(userID, num_recommendations). These recommendations are only artist ids. We have to map them to artist names by using data in artist_data.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06S8db0uNVZj",
        "outputId": "3cf61cc7-f30f-44d9-b601-654e83e37d37"
      },
      "source": [
        "# Make five reccommendations to user 2093760\r\n",
        "recommendations = (model.recommendProducts(2093760,5))\r\n",
        "print(recommendations)\r\n",
        "# construct set of recommendated artists\r\n",
        "recArtist = set(rating[1] for rating in recommendations)\r\n",
        "recArtist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Rating(user=2093760, product=1007614, rating=0.03256146088134991), Rating(user=2093760, product=4605, rating=0.030157940809915088), Rating(user=2093760, product=2814, rating=0.02971024620347483), Rating(user=2093760, product=1037970, rating=0.029325039246548064), Rating(user=2093760, product=829, rating=0.029183666035929826)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{829, 2814, 4605, 1007614, 1037970}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipcVwdKNbFi"
      },
      "source": [
        "# construct data of artists (artist_id, artist_name)\r\n",
        "\r\n",
        "rawArtistData = sc.textFile(base + \"artist_data.txt\")\r\n",
        "\r\n",
        "def xtractFields(s):\r\n",
        "    line = re.split(\"\\s|\\t\",s,1)\r\n",
        "    if (len(line) > 1):\r\n",
        "        try:\r\n",
        "            return (int(line[0]), str(line[1].strip()))\r\n",
        "        except ValueError:\r\n",
        "            return (-1,\"\")\r\n",
        "    else: \r\n",
        "        return (-1,\"\")\r\n",
        "\r\n",
        "artistByID = rawArtistData.map(xtractFields).filter(lambda x: x[0] > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx12A6VLNd7A",
        "outputId": "b11ef08b-29ca-44a0-b065-7e392dfa6c50"
      },
      "source": [
        "# Filter in those artists, get just artist, and print\r\n",
        "def artistNames(line):\r\n",
        "#     [artistID, name]\r\n",
        "    if (line[0] in recArtist):\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "recList = artistByID.filter(artistNames).values().collect()\r\n",
        "\r\n",
        "print(recList)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['50 Cent', 'Snoop Dogg', 'Nas', 'Jay-Z', 'Kanye West']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W12Y__4nNjfv"
      },
      "source": [
        "**IMPORTANT NOTE**  \r\n",
        "At the moment, it is necessary to manually unpersist the RDDs inside the model when you are done with it. The following function can be used to make sure models are promptly uncached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EGHJtwyNg2w"
      },
      "source": [
        "def unpersist(model):\r\n",
        "    model.userFeatures().unpersist()\r\n",
        "    model.productFeatures().unpersist()\r\n",
        "\r\n",
        "# uncache data and model when they are no longer used  \r\n",
        "unpersist(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrnV-grGNneY"
      },
      "source": [
        "## **Evaluating Recommendation Quality**\r\n",
        "In this section, we study how to evaluate the quality of our model. It's hard to say how good the recommendations are. One of serveral methods approach to evaluate a recommender based on its ability to rank good items (artists) high in a list of recommendations. The problem is how to define \"good artists\". Currently, by training all data, \"good artists\" is defined as \"artists the user has listened to\", and the recommender system has already received all of this information as input. It could trivially return the users previously-listened artists as top recommendations and score perfectly. Indeed, this is not useful, because the recommender's is used to recommend artists that the user has never listened to.\r\n",
        "\r\n",
        "To overcome that problem, we can hide the some of the artist play data and only use the rest to train model. Then, this held-out data can be interpreted as a collection of \"good\" recommendations for each user. The recommender is asked to rank all items in the model, and the rank of the held-out artists are examined. Ideally the recommender places all of them at or near the top of the list.\r\n",
        "\r\n",
        "The recommender's score can then be computed by comparing all held-out artists' ranks to the rest. The fraction of pairs where the held-out artist is ranked higher is its score. 1.0 is perfect, 0.0 is the worst possible score, and 0.5 is the expected value achieved from randomly ranking artists.\r\n",
        "\r\n",
        "AUC(Area Under the Curve) can be used as a metric to evaluate model. It is also viewed as the probability that a randomly-chosen \"good\" artist ranks above a randomly-chosen \"bad\" artist.\r\n",
        "\r\n",
        "Next, we split the training data into 2 parts: trainData and cvData with ratio 0.7:0.3 respectively, where trainData is the dataset that will be used to train model. Then we write a function to calculate AUC to evaluate the quality of our model.\r\n",
        "\r\n",
        "Split the data into trainData and cvData with ratio 0.9:0.1 and use the first part to train a statistic model with:\r\n",
        "- rank=10\r\n",
        "- iterations=5\r\n",
        "- lambda_=0.01\r\n",
        "- alpha=1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH8qORjhNmj0",
        "outputId": "d56dea2a-a019-4bd4-eb92-ee4326ff985b"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.7,0.3],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[389] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMsbanFaN2-o"
      },
      "source": [
        "**Here I just split the dataset to 70% for training and 30% for testing. If I have enough time, I will conduct an experiment that changing the proportion of splitting data to see how it affects our prediction model. (See it at Addition work)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1TH4n3CNyn9",
        "outputId": "d416f669-bdd5-4afc-e4ff-8a223bccc8e0"
      },
      "source": [
        "#training\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=iterations,lambda_=lambda_ ,alpha=alpha)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish training model in 184.436095 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXie6B5PN8un"
      },
      "source": [
        "## **Area under the ROC curve: a function to compute it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLJJK_uN6jj"
      },
      "source": [
        "# Get all unique artistId, and broadcast them\r\n",
        "allItemIDs = np.array(allData.map(lambda x: x[1]).distinct().collect())\r\n",
        "bAllItemIDs = sc.broadcast(allItemIDs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt2ItIepOCp7"
      },
      "source": [
        "from random import randint\r\n",
        "\r\n",
        "# Depend on the number of item in userIDAndPosItemIDs,\r\n",
        "# create a set of \"negative\" products for each user. These are randomly chosen\r\n",
        "# from among all of the other items, excluding those that are \"positive\" for the user.\r\n",
        "# NOTE 1: mapPartitions operates on many (user,positive-items) pairs at once\r\n",
        "# NOTE 2: flatMap breaks the collections above down into one big set of tuples\r\n",
        "def xtractNegative(userIDAndPosItemIDs):\r\n",
        "    def pickEnoughNegatives(line):\r\n",
        "        userID = line[0]\r\n",
        "        posItemIDSet = set(line[1])\r\n",
        "        #posItemIDSet = line[1]\r\n",
        "        negative = []\r\n",
        "        allItemIDs = bAllItemIDs.value\r\n",
        "        # Keep about as many negative examples per user as positive. Duplicates are OK.\r\n",
        "        i = 0\r\n",
        "        while (i < len(allItemIDs) and len(negative) < len(posItemIDSet)):\r\n",
        "            itemID = allItemIDs[randint(0,len(allItemIDs)-1)]\r\n",
        "            if itemID not in posItemIDSet:\r\n",
        "                negative.append(itemID)\r\n",
        "            i += 1\r\n",
        "        \r\n",
        "        # Result is a collection of (user,negative-item) tuples\r\n",
        "        return map(lambda itemID: (userID, itemID), negative)\r\n",
        "\r\n",
        "    # Init an RNG and the item IDs set once for partition\r\n",
        "    # allItemIDs = bAllItemIDs.value\r\n",
        "    return map(pickEnoughNegatives, userIDAndPosItemIDs)\r\n",
        "def ratioOfCorrectRanks(positiveRatings, negativeRatings):\r\n",
        "    \r\n",
        "    # find number elements in arr that has index >= start and has value smaller than x\r\n",
        "    # arr is a sorted array\r\n",
        "    def findNumElementsSmallerThan(arr, x, start=0):\r\n",
        "        left = start\r\n",
        "        right = len(arr) -1\r\n",
        "        # if x is bigger than the biggest element in arr\r\n",
        "        if start > right or x > arr[right]:\r\n",
        "            return right + 1\r\n",
        "        mid = -1\r\n",
        "        while left <= right:\r\n",
        "            mid = (left + right) // 2\r\n",
        "            if arr[mid] < x:\r\n",
        "                left = mid + 1\r\n",
        "            elif arr[mid] > x:\r\n",
        "                right = mid - 1\r\n",
        "            else:\r\n",
        "                while mid-1 >= start and arr[mid-1] == x:\r\n",
        "                    mid -= 1\r\n",
        "                return mid\r\n",
        "        return mid if arr[mid] > x else mid + 1\r\n",
        "    \r\n",
        "    ## AUC may be viewed as the probability that a random positive item scores\r\n",
        "    ## higher than a random negative one. Here the proportion of all positive-negative\r\n",
        "    ## pairs that are correctly ranked is computed. The result is equal to the AUC metric.\r\n",
        "    correct = 0 ## L\r\n",
        "    total = 0 ## L\r\n",
        "    \r\n",
        "    # sorting positiveRatings array needs more cost\r\n",
        "    #positiveRatings = np.array(map(lambda x: x.rating, positiveRatings))\r\n",
        "\r\n",
        "    negativeRatings = list(map(lambda x:x.rating, negativeRatings))\r\n",
        "    \r\n",
        "    #np.sort(positiveRatings)\r\n",
        "    negativeRatings.sort()# = np.sort(negativeRatings)\r\n",
        "    total = len(positiveRatings)*len(negativeRatings)\r\n",
        "    \r\n",
        "    for positive in positiveRatings:\r\n",
        "        # Count the correctly-ranked pairs\r\n",
        "        correct += findNumElementsSmallerThan(negativeRatings, positive.rating)\r\n",
        "        \r\n",
        "    ## Return AUC: fraction of pairs ranked correctly\r\n",
        "    return float(correct) / total\r\n",
        "\r\n",
        "def calculateAUC(positiveData, bAllItemIDs, predictFunction):\r\n",
        "    # Take held-out data as the \"positive\", and map to tuples\r\n",
        "    positiveUserProducts = positiveData.map(lambda r: (r[0], r[1]))\r\n",
        "    # Make predictions for each of them, including a numeric score, and gather by user\r\n",
        "    positivePredictions = predictFunction(positiveUserProducts).groupBy(lambda r: r.user)\r\n",
        "    \r\n",
        "    # Create a set of \"negative\" products for each user. These are randomly chosen \r\n",
        "    # from among all of the other items, excluding those that are \"positive\" for the user. \r\n",
        "    negativeUserProducts = positiveUserProducts.groupByKey().mapPartitions(xtractNegative).flatMap(lambda x: x)\r\n",
        "    # Make predictions on the rest\r\n",
        "    negativePredictions = predictFunction(negativeUserProducts).groupBy(lambda r: r.user)\r\n",
        "    \r\n",
        "    return (\r\n",
        "            positivePredictions.join(negativePredictions)\r\n",
        "                .values()\r\n",
        "                .map(\r\n",
        "                    lambda positive_negativeRatings: ratioOfCorrectRanks(positive_negativeRatings[0], positive_negativeRatings[1])\r\n",
        "                )\r\n",
        "                .mean()\r\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmnB94QQOMGS"
      },
      "source": [
        "**Using part cvData and function calculateAUC to compute the AUC of the trained model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3sE1SBVOKUQ",
        "outputId": "3403a043-b2b4-4c17-d30e-7bea23907d15"
      },
      "source": [
        "t0 = time()\r\n",
        "auc = calculateAUC( cvData,bAllItemIDs, model.predictAll)\r\n",
        "t1 = time()\r\n",
        "print(\"auc=\",auc)\r\n",
        "print(\"finish in %f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc= 0.9613591452203921\n",
            "finish in 469.166578 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qF_QN0OQAO"
      },
      "source": [
        "**Now we have the AUC of our model, it’s helpful to benchmark this against a simpler approach. For example, consider recommending the globally most-played artists to every user. This is not personalized, but is simple and may be effective.**\r\n",
        "\r\n",
        "Implement this simple pupolarity-based prediction algorithm, evaluate its AUC score, and compare to the results achieved by the more sophisticated ALS algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ZK5MGpOPH5"
      },
      "source": [
        "bListenCount = sc.broadcast(trainData.map(lambda r: (r[1], r[2])).reduceByKey(lambda x,y: x+y).collectAsMap())\r\n",
        "def predictMostListened(allData):\r\n",
        "    return allData.map(lambda r: Rating(r[0], r[1], bListenCount.value.get( r[1], 0.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGxv6YWkOWgn",
        "outputId": "2cd14e81-fbdc-4fef-c56c-1558fc10ec64"
      },
      "source": [
        "auc = calculateAUC(cvData,bListenCount, predictMostListened)\r\n",
        "print(\"AUC score:\" + str(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score:0.936190567916563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YokAaTtGOant"
      },
      "source": [
        "**Personalized recommendations with ALS: Hyperparameters tuning**  \r\n",
        "\r\n",
        "In the previous section, we build our models with some given paramters without any knowledge about them. Actually, choosing the best parameters' values is very important. It can significantly affect the quality of models. Especially, with the current implementation of ALS in MLLIB, these parameters are not learned by the algorithm, and must be chosen by the caller. The following parameters should get consideration before training models:\r\n",
        "\r\n",
        "- rank = 10: the number of latent factors in the model, or equivalently, the number of columns $k$ in the user-feature and product-feature matrices. In non-trivial cases, this is also their rank.\r\n",
        "\r\n",
        "- iterations = 5: the number of iterations that the factorization runs. Instead of runing the algorithm until RMSE converged which actually takes very long time to finish with large datasets, we only let it run in a given number of iterations. More iterations take more time but may produce a better factorization.\r\n",
        "\r\n",
        "- lambda_ = 0.01: a standard overfitting parameter. Higher values resist overfitting, but values that are too high hurt the factorization's accuracy.\r\n",
        "\r\n",
        "- alpha = 1.0: controls the relative weight of observed versus unobserved userproduct interactions in the factorization.\r\n",
        "\r\n",
        "Although all of them have impact on the models' quality, iterations is more of a constraint on resources used in the factorization. So, rank, lambda_ and alpha can be considered hyperparameters to the model. We will try to find \"good\" values for them. Indeed, the values of hyperparameter are not necessarily optimal. Choosing good hyperparameter values is a common problem in machine learning. The most basic way to choose values is to simply try combinations of values and evaluate a metric for each of them, and choose the combination that produces the best value of the metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gecOYacsOqjA"
      },
      "source": [
        "## **Grid Search**\r\n",
        "For simplicity, assume that we want to explore the following parameter space: $ rank \\in \\{10, 50\\}$, $lambda\\_ \\in \\{1.0, 0.0001\\}$ and $alpha \\in \\{1.0, 40.0\\}$.   \r\n",
        "\r\n",
        "Find the best combination of them in terms of the highest AUC value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y8udZJhOYnx",
        "outputId": "4a35b60a-c804-4581-84a4-793cd1f2fdb4"
      },
      "source": [
        "evaluations = []\r\n",
        "\r\n",
        "for rank in [10, 50]:\r\n",
        "    for lambda_ in [1.0, 0.0001]:\r\n",
        "        for alpha in [1.0, 40.0]:\r\n",
        "            print(\"Train model with rank=%d lambda_=%f alpha=%f\" % (rank, lambda_, alpha))\r\n",
        "            # with each combination of params, we should run multiple times and get avg\r\n",
        "            # for simple, we only run one time.\r\n",
        "            model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=5,lambda_=lambda_ ,alpha=alpha)\r\n",
        "            auc = calculateAUC(cvData,bListenCount,model.predictAll)\r\n",
        "\r\n",
        "            evaluations.append(((rank, lambda_, alpha), auc))\r\n",
        "\r\n",
        "            unpersist(model)\r\n",
        "\r\n",
        "evaluations.sort(key = lambda x: -x[1])\r\n",
        "evalDataFrame = pd.DataFrame(data=evaluations)\r\n",
        "print(evalDataFrame)\r\n",
        "\r\n",
        "trainData.unpersist()\r\n",
        "cvData.unpersist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model with rank=10 lambda_=1.000000 alpha=1.000000\n",
            "Train model with rank=10 lambda_=1.000000 alpha=40.000000\n",
            "Train model with rank=10 lambda_=0.000100 alpha=1.000000\n",
            "Train model with rank=10 lambda_=0.000100 alpha=40.000000\n",
            "Train model with rank=50 lambda_=1.000000 alpha=1.000000\n",
            "Train model with rank=50 lambda_=1.000000 alpha=40.000000\n",
            "Train model with rank=50 lambda_=0.000100 alpha=1.000000\n",
            "Train model with rank=50 lambda_=0.000100 alpha=40.000000\n",
            "                    0         1\n",
            "0     (10, 1.0, 40.0)  0.972875\n",
            "1  (10, 0.0001, 40.0)  0.972592\n",
            "2     (50, 1.0, 40.0)  0.970980\n",
            "3  (50, 0.0001, 40.0)  0.970035\n",
            "4      (10, 1.0, 1.0)  0.964881\n",
            "5   (10, 0.0001, 1.0)  0.960176\n",
            "6      (50, 1.0, 1.0)  0.959316\n",
            "7   (50, 0.0001, 1.0)  0.943075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[389] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa_8yMC_O1sC"
      },
      "source": [
        "**The combination of parameters that gets the highest AUC is: rank = 10 ; lambda = 1.0 ; alpha = 40**  \r\n",
        "**Using \"optimal\" hyper-parameters obtained, re-train the model and show top-5 artist names recommendated for user 2093760.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X3cZRtHcOvl-",
        "outputId": "12d89bea-e8c4-47a3-c611-0572bd3c5942"
      },
      "source": [
        "model = ALS.trainImplicit(ratings=trainData, rank=10, iterations=5, lambda_=1.0, alpha=40.0)\r\n",
        "allData.unpersist()\r\n",
        "\r\n",
        "userID = 2093760\r\n",
        "recommendations = model.recommendProducts(userID,5)\r\n",
        "\r\n",
        "recArtist = set(rating[1] for rating in recommendations)\r\n",
        "\r\n",
        "# Filter in those artists, get just artist, and print\r\n",
        "def artistNames(line):\r\n",
        "#     [artistID, name]\r\n",
        "    if (line[0] in recArtist):\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "recList = artistByID.filter(artistNames).values().collect()\r\n",
        "print(recList)\r\n",
        "\r\n",
        "unpersist(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bright Eyes', 'The Clash', 'The Cure', 'The Killers', 'Weezer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjMdSEuQPB0_"
      },
      "source": [
        "**It seems that the result of top 5 recommended artists does not change when we add more parameters to the model or modify them (such as lambda, alpha). I think that we should extend to top 50 or top 70 to see how the recommendation changing. Because I think that lambda and alpha parameters affect only when the rating of each artist approximate the mean of total ratings for one user (Top 5 artists have the much larger rating value than others, top 5 artists do not change with modified parameter)**  \r\n",
        "**This raises me the question that how strong the impact of those parameters? Is it really nessessary to put into our model when we just need to retrieve a small number of top artists (let's say, less than top 10)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIdS97tFPGNB"
      },
      "source": [
        "## **Changing the proportion of splitting data**  \r\n",
        "**In this experiment, I will change the percentage of training data to 50%, 80%, 90% and 99% respectively. The purpose is to observe the changing of AUC score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgqqNWI0O69m"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.5,0.5],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=iterations,lambda_=lambda_ ,alpha=alpha)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "auc = calculateAUC( cvData,bAllItemIDs, model.predictAll)\r\n",
        "t1 = time()\r\n",
        "print(\"auc=\",auc)\r\n",
        "print(\"finish in %f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ld8oQtCPNr5"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.8,0.2],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=iterations,lambda_=lambda_ ,alpha=alpha)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "auc = calculateAUC( cvData,bAllItemIDs, model.predictAll)\r\n",
        "t1 = time()\r\n",
        "print(\"auc=\",auc)\r\n",
        "print(\"finish in %f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zw6fjk_PP47"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.9,0.1],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=iterations,lambda_=lambda_ ,alpha=alpha)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "auc = calculateAUC( cvData,bAllItemIDs, model.predictAll)\r\n",
        "t1 = time()\r\n",
        "print(\"auc=\",auc)\r\n",
        "print(\"finish in %f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V9BNezYPRld"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.99,0.01],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "model = ALS.trainImplicit(ratings=trainData,rank=rank,iterations=iterations,lambda_=lambda_ ,alpha=alpha)\r\n",
        "t1 = time()\r\n",
        "print(\"finish training model in %f secs\" % (t1 - t0))\r\n",
        "\r\n",
        "t0 = time()\r\n",
        "auc = calculateAUC( cvData,bAllItemIDs, model.predictAll)\r\n",
        "t1 = time()\r\n",
        "print(\"auc=\",auc)\r\n",
        "print(\"finish in %f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORsRtWlqPU8q"
      },
      "source": [
        "**As the above results, we have:**  \r\n",
        "\r\n",
        "**training 50% -> AUC: 0.9557431751634355**  \r\n",
        "**training 80% -> AUC: 0.9633452139683835**  \r\n",
        "**training 90% -> AUC: 0.9641551756487843**  \r\n",
        "**training 99% -> AUC: 0.9672845649647493**\r\n",
        "\r\n",
        "**This is obviouly that the proportion of splitting data does affect the result of the AUC score. The more training data, the higher AUC score. In my opinion, having higher AUC score does not mean that the model is working well in general. Because high percentage of training data may prone to overfitting.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btwX7u7fPgPG"
      },
      "source": [
        "## **Expand the the list of recommended artist**\r\n",
        "**As my hypothesis, in this experiment, instead of retrieving top 5 artist, I try to retrieve top 50 and 70 artist with modified parameters to see the differences the result compare to the model with standard parameters.  **\r\n",
        "**Model with standard parameters (lambda and alpha are set by default)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYbmUcYuPS_h"
      },
      "source": [
        "trainData, cvData = allData.randomSplit([0.7,0.3],1)\r\n",
        "trainData.cache()\r\n",
        "cvData.cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQc7TvrrPm-o"
      },
      "source": [
        "model50 = ALS.trainImplicit(ratings=trainData, rank=10, iterations=5)\r\n",
        "trainData.unpersist()\r\n",
        "\r\n",
        "userID = 2093760\r\n",
        "recommendations50 = model50.recommendProducts(userID,50)\r\n",
        "\r\n",
        "recArtist = set(rating[1] for rating in recommendations50)\r\n",
        "\r\n",
        "recList50 = artistByID.filter(artistNames).values().collect()\r\n",
        "\r\n",
        "print(recList50)\r\n",
        "\r\n",
        "unpersist(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7kllWkHPqqE"
      },
      "source": [
        "### Model with lamda = 0.0001 , alpha = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AdG7s_VPowr"
      },
      "source": [
        "model50_1 = ALS.trainImplicit(ratings=trainData, rank=10, iterations=5, lambda_= 0.0001, alpha= 40.0)\r\n",
        "trainData.unpersist()\r\n",
        "\r\n",
        "userID = 2093760\r\n",
        "recommendations50_1 = model50_1.recommendProducts(userID,50)\r\n",
        "\r\n",
        "recArtist = set(rating[1] for rating in recommendations50_1)\r\n",
        "\r\n",
        "recList50_1 = artistByID.filter(artistNames).values().collect()\r\n",
        "\r\n",
        "print(recList50_1)\r\n",
        "\r\n",
        "unpersist(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPflKlxkPukz"
      },
      "source": [
        "temp3 = [item for item in recList50 if item not in recList50_1]\r\n",
        "print(temp3)\r\n",
        "print(\"\\n Number of different artists between standard model and model_1:\" + str(len(temp3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJp2LmdTPxwr"
      },
      "source": [
        "### Model with lambda = 0.1, alpha = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-A04S5PPv-0"
      },
      "source": [
        "model50_2 = ALS.trainImplicit(ratings=trainData, rank=10, iterations=5, lambda_= 0.1, alpha= 1.0)\r\n",
        "trainData.unpersist()\r\n",
        "\r\n",
        "userID = 2093760\r\n",
        "recommendations50_2 = model50_2.recommendProducts(userID,50)\r\n",
        "\r\n",
        "recArtist = set(rating[1] for rating in recommendations50_2)\r\n",
        "\r\n",
        "recList50_2 = artistByID.filter(artistNames).values().collect()\r\n",
        "\r\n",
        "print(recList50_2)\r\n",
        "\r\n",
        "unpersist(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFKhd0C2P1Ni"
      },
      "source": [
        "temp4 = [item for item in recList50 if item not in recList50_2]\r\n",
        "print(temp4)\r\n",
        "print(\"\\n Number of different artists between standard model and model_2:\" + str(len(temp4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2LHW6NUP6vg"
      },
      "source": [
        "### Conclusion: \r\n",
        "**As the result has shown above, I dont need to expand the result list to top 70 artists anymore. It is clearly proving my hypothesis is true.**  \r\n",
        "\r\n",
        "**How we configure the lambda and alpha makes a huge impact on the retrieved result: In my example, the top artists that highly recommended to user=\"2093760\" is ['50Cent', 'Snoopdog', Notorious B.I.G] (they appear in both standard model and modified models). Others artists may vary from different models.**   \r\n",
        "\r\n",
        "**We may not need to include lambda and alpha to the model if we only retreive the top result less than 10 artists.**   \r\n",
        "\r\n",
        "### **Proposed method:**\r\n",
        "**In my opinion: We should cut out outliers (top 5 artists). With this method, recommendation will be more diverse and accurate.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtGMZCkfP3xS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}